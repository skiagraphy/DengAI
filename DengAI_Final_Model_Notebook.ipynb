{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75108f91",
   "metadata": {},
   "source": [
    "# DengAI: Predicting Disease Spread\n",
    "\n",
    "Forecasting weekly dengue cases in San Juan and Iquitos using climate, environmental, and public health features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891c4aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load training data\n",
    "features = pd.read_csv('dengue_features_train.csv')\n",
    "labels = pd.read_csv('dengue_labels_train.csv')\n",
    "\n",
    "# Merge\n",
    "df = pd.merge(features, labels, on=[\"city\", \"year\", \"weekofyear\"])\n",
    "df[\"week_start_date\"] = pd.to_datetime(df[\"week_start_date\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585f0b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(method='ffill', inplace=True)\n",
    "df.fillna(method='bfill', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424e6e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sj = df[df[\"city\"] == \"sj\"].copy()\n",
    "iq = df[df[\"city\"] == \"iq\"].copy()\n",
    "\n",
    "sj[\"city_code\"] = 0\n",
    "iq[\"city_code\"] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea03218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lag_features(df, features, lags):\n",
    "    for feature in features:\n",
    "        for lag in lags:\n",
    "            df[f\"{feature}_lag{lag}\"] = df[feature].shift(lag)\n",
    "    return df\n",
    "\n",
    "lag_features = [\"precipitation_amt_mm\", \"reanalysis_air_temp_k\", \"reanalysis_relative_humidity_percent\"]\n",
    "sj = create_lag_features(sj, lag_features, lags=[1, 2, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc84bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rolling_features(df, features, windows):\n",
    "    for feature in features:\n",
    "        for window in windows:\n",
    "            df[f\"{feature}_roll{window}\"] = df[feature].rolling(window=window, min_periods=1).mean()\n",
    "    return df\n",
    "\n",
    "sj = create_rolling_features(sj, lag_features, windows=[3, 5, 8, 12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a3c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sj[\"intervention_active\"] = ((sj[\"week_start_date\"] >= \"1994-11-01\") & (sj[\"week_start_date\"] <= \"1995-03-31\")).astype(int)\n",
    "sj[\"major_outbreak_season\"] = (((sj[\"week_start_date\"] >= \"1991-08-01\") & (sj[\"week_start_date\"] <= \"1992-03-31\")) | ((sj[\"week_start_date\"] >= \"1994-05-01\") & (sj[\"week_start_date\"] <= \"1995-06-30\"))).astype(int)\n",
    "sj[\"post_hurricane_georges\"] = ((sj[\"week_start_date\"] >= \"1998-09-21\") & (sj[\"week_start_date\"] <= \"1999-05-31\")).astype(int)\n",
    "\n",
    "years_from_1990 = sj[\"week_start_date\"].dt.year - 1990\n",
    "sj[\"migration_index\"] = -1 * (years_from_1990 / 10.0).clip(0, 1)\n",
    "\n",
    "for flag in [\"intervention_active\", \"major_outbreak_season\", \"post_hurricane_georges\"]:\n",
    "    sj[f\"{flag}_lag1\"] = sj[flag].shift(1)\n",
    "    sj[f\"{flag}_lag2\"] = sj[flag].shift(2)\n",
    "\n",
    "sj.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67514330",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sj.drop(columns=[\"city\", \"week_start_date\", \"total_cases\"])\n",
    "y = sj[\"total_cases\"]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Final model: XGBoost\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=250,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "rmse_scores = []\n",
    "mae_scores = []\n",
    "\n",
    "for train_idx, test_idx in tscv.split(X_scaled):\n",
    "    model.fit(X_scaled[train_idx], y.iloc[train_idx])\n",
    "    y_pred = model.predict(X_scaled[test_idx])\n",
    "    rmse_scores.append(np.sqrt(mean_squared_error(y.iloc[test_idx], y_pred)))\n",
    "    mae_scores.append(mean_absolute_error(y.iloc[test_idx], y_pred))\n",
    "\n",
    "print(\"Average RMSE:\", np.mean(rmse_scores))\n",
    "print(\"Average MAE:\", np.mean(mae_scores))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
